{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MOntecarlo-parte1-copula.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPIE1Nh4ldVysTlmcTyv73T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WuilsonEstacio/github-para-estadistica/blob/main/MOntecarlo_parte1_copula.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3i7hqCFNsPa"
      },
      "source": [
        "# Montecarlo\n",
        "La cópula gaussiana es una cópula construida a partir de una distribución normal multivariada. Si quieren ver las matemáticas pueden revisar wikipedia en este link).\n",
        "\n",
        "El método para generer números aleatorios correlacionados con una cópula gaussiana es el siguiente:\n",
        "\n",
        "A partir de la matriz de correlación calculamos la matriz $L$(descomposición de Cholesky).\n",
        "Generamos una matriz $x$ de números aleatorios independientes con distribución $N(0,1)$.\n",
        "Calculamos la matriz $s = x * L^T$.\n",
        "Aplicamos la función de distribución acumulativa normal $\\phi$ a la matriz $s$, de la forma: $U = \\phi(s)$.\n",
        "Aplicamos la función de distribución que querramos a cada columna de $U$.\n",
        "Ahora vamos a mostrar un ejemplo =D. Empezamos cargando una información de precios y calculamos su matriz de correlacion:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "E2MO8cpKNiow",
        "outputId": "f2de3157-c7f4-42cc-9aad-5cc3d4106532"
      },
      "source": [
        "import numpy as np\n",
        "import scipy.stats as st\n",
        "import pandas as pd\n",
        "\n",
        "#data = pd.read_excel('Data Prices.xlsx', index_col = 0).sort_index()\n",
        "data = pd.read_excel('/content/Data Prices.xlsx', index_col = 0).sort_index()\n",
        "data = data.pct_change().dropna().iloc[:,[1,2,6]]\n",
        "\n",
        "cov = np.cov(data.values.T)\n",
        "mu = np.mean(data.values, axis=0)\n",
        "desv = np.sqrt(np.diag(cov))\n",
        "correl = np.corrcoef(data.values.T)\n",
        "\n",
        "print(\"Vector de Medias Original:\")\n",
        "print(mu)\n",
        "print(\"\")\n",
        "print(\"Vector de Desviacion Estandar Original:\")\n",
        "print(desv)\n",
        "print(\"\")\n",
        "print(\"Matriz de Covarianza Original:\")\n",
        "print(cov)\n",
        "print(\"\")\n",
        "print(\"Matriz de Correlación Original:\")\n",
        "print(correl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-57775171792c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#data = pd.read_excel('Data Prices.xlsx', index_col = 0).sort_index()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/Data Prices.xlsx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpct_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    871\u001b[0m                     \u001b[0;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1444\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_has_valid_tuple\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Too many indexers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_key\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1365\u001b[0m             \u001b[0;31m# check that the key does not exceed the maximum size of the index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"positional indexers are out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1368\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Can only index by location with a [{self._valid_types}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32GVhAbEOnvI"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def hist_scatter(x, y, bins=50):\n",
        "    g = sns.JointGrid(x=x, y=y)\n",
        "    g = g.plot_joint(sns.scatterplot, color=\"b\", alpha=.6)\n",
        "    _ = g.ax_marg_x.hist(x, color=\"r\", alpha=.6,\n",
        "                         bins=bins)\n",
        "    _ = g.ax_marg_y.hist(y, color=\"green\", alpha=.6,\n",
        "                         orientation=\"horizontal\",\n",
        "                         bins=bins)\n",
        "\n",
        "np.random.seed(0)\n",
        "x = np.random.randn(1000, 2)\n",
        "hist_scatter(x[:,0], x[:,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoF90JOyOowg"
      },
      "source": [
        "rs = np.random.RandomState(seed = 0)\n",
        "n = 10000\n",
        "m = data.shape[1]\n",
        "x = rs.randn(n, m)\n",
        "x = np.matrix(x)\n",
        "L = np.linalg.cholesky(correl)\n",
        "\n",
        "s1 = x * L.T\n",
        "U1 = st.norm.cdf(s1)\n",
        "\n",
        "x1 = st.norm.ppf(U1)\n",
        "x1 = np.multiply(x1, desv) + mu\n",
        "\n",
        "mu_1 = np.mean(x1, axis=0)\n",
        "cov_1 = np.cov(x1.T)\n",
        "correl_1 = np.corrcoef(x1.T)\n",
        "\n",
        "print(\"Vector de Medias Original:\")\n",
        "print(mu)\n",
        "print(\"\")\n",
        "print(\"Vector de Medias Simulado:\")\n",
        "print(mu_1)\n",
        "print(\"\")\n",
        "print(\"Matriz de Covarianza Original:\")\n",
        "print(cov)\n",
        "print(\"\")\n",
        "print(\"Matriz de Covarianza Simulada:\")\n",
        "print(cov_1)\n",
        "print(\"\")\n",
        "print(\"Matriz de Correlación Original:\")\n",
        "print(correl)\n",
        "print(\"\")\n",
        "print(\"Matriz de Correlación Simulada:\")\n",
        "print(correl_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoG93oudOvh0"
      },
      "source": [
        "Se puede ver que la serie generada tiene una correlacion similar a la original, sin embargo no es igual. Si graficamos la relación de la primera con segunda columna de $x1$ se obtiene el siguiente grafico"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzQlMqQqOwap"
      },
      "source": [
        "#Graficando la relacion de la primera y segunda serie simulada\n",
        "hist_scatter(x1[:,0], x1[:,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhseR3S5O5UJ"
      },
      "source": [
        "Sin embargo he descubierto un truco para que la correlación generada sea exactamente igual. Para ello se realiza lo siguiente:\n",
        "\n",
        "Luego de generar la matriz $x$ calculamos su matriz de covarianzas.\n",
        "Aplicamos la factorización de Cholesky sobre la matriz de covarianzas y calculamos $L1$.\n",
        "Calculamos la inversa de $L1$.\n",
        "Actualizamos $x$ con la siguiente formula: $x = x * L1^{-1}$.\n",
        "Repetimos este proceso como 3 veces y sobre el nuevo $x$ aplicamos la matriz $L$ del método original.\n",
        "Ahora vamos a ver un ejemplo =D para que vean como se hace:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqTGax0OO6I3"
      },
      "source": [
        "x = rs.randn(n, m)\n",
        "x = np.matrix(x)\n",
        "for i in range(0,3):\n",
        "    c1 = np.cov(x.T)\n",
        "    L1 = np.linalg.cholesky(c1)\n",
        "    L1 = np.matrix(L1).I\n",
        "    x = x * L1.T\n",
        "\n",
        "s2 = x * L.T\n",
        "U2 = st.norm.cdf(s2)\n",
        "x2 = st.norm.ppf(U2)\n",
        "x2 = np.multiply(x2, desv) + mu\n",
        "\n",
        "mu_2 = np.mean(x2, axis=0)\n",
        "cov_2 = np.cov(x2.T)\n",
        "correl_2 = np.corrcoef(x2.T)\n",
        "\n",
        "print(\"Vector de Medias Original:\")\n",
        "print(mu)\n",
        "print(\"\")\n",
        "print(\"Vector de Medias Simulado con el ajuste:\")\n",
        "print(mu_2)\n",
        "print(\"\")\n",
        "print(\"Matriz de Covarianza Original:\")\n",
        "print(cov)\n",
        "print(\"\")\n",
        "print(\"Matriz de Covarianza Simulada con el ajuste:\")\n",
        "print(cov_2)\n",
        "print(\"\")\n",
        "print(\"Matriz de Correlación Original:\")\n",
        "print(correl)\n",
        "print(\"\")\n",
        "print(\"Matriz de Correlación Simulada con el ajuste:\")\n",
        "print(correl_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkOUYwtDPDXO"
      },
      "source": [
        "Ahora podran ver que ambas matrices son identicas, con esto se mejora la precision de la simulación. Si graficamos la relación de la primera con segunda columna de $x2$ se obtiene el siguiente grafico"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANGonUx-PD8t"
      },
      "source": [
        "hist_scatter(x2[:,0], x2[:,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmMWkuQQPJLO"
      },
      "source": [
        "Ahora para demostrar que podemos generar cualquier tipo de distribución correlacionada, usando la simulación anterior aplicaremos las inversas acumulativas de las distribuciones normal, t y uniforme para calcular las nuevas distribuciones correlacionadas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGsMnhhiO_gv"
      },
      "source": [
        "x3 = st.norm.ppf(U2)\n",
        "x3[:,0] = st.norm.ppf(U2[:,0], loc=0.5, scale=0.3)\n",
        "x3[:,1] = st.t.ppf(U2[:,1], df = n - 1)\n",
        "x3[:,2] = st.uniform.ppf(U2[:,2])\n",
        "\n",
        "correl_3 = np.corrcoef(x3.T)\n",
        "\n",
        "print(\"Matriz de Correlación Original:\")\n",
        "print(correl)\n",
        "print(\"\")\n",
        "print(\"Matriz de Correlación Simulada con el ajuste:\")\n",
        "print(correl_3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxUQPtBtPQuo"
      },
      "source": [
        "hist_scatter(x3[:,0], x3[:,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlY-ZyqgPT4A"
      },
      "source": [
        "Graficando la relacion de la serie con distribucion normal y uniforme\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_D8Ie9APWDf"
      },
      "source": [
        "hist_scatter(x3[:,0], x3[:,2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhMp4iTlPcX3"
      },
      "source": [
        "Y con eso pueden ver que se han generados muestras de distintas distribuciones correlacionadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLOqGPC7Pe6g"
      },
      "source": [
        "B. Cópula t-Student.\n",
        "La cópula t-Student es una cópula construida a partir de una distribución t-Student multivariada. Si quieren ver las matemáticas pueden revisar el paper de este link.\n",
        "\n",
        "El método para generer números aleatorios correlacionados con una cópula t-Student es el siguiente:\n",
        "\n",
        "A partir de la matriz de correlación calculamos la matriz $L$(descomposición de Cholesky).\n",
        "Calculamos los grados de libertad con la fórmua $\\nu = (n-1)*d$, donde $d$ es el numero de dimensiones y $n$ el número de observaciones a simular.\n",
        "Generamos un vector $V$ de dimension de números aleatorios independientes con distribución $\\chi(\\nu)$.\n",
        "Generamos una matriz $x$ de números aleatorios independientes con distribución $N(0,1)$.\n",
        "Calculamos la matriz $s = \\sqrt{\\frac{\\nu}{V}} * (x * L^T)$.\n",
        "Aplicamos la función de distribución acumulativa t-Student $t_{\\nu}$ a la matriz $s$, de la forma: $U = t_{\\nu}(s)$.\n",
        "Aplicamos la función de distribución que querramos a cada columna de $U$.\n",
        "Ahora vamos a mostrar un ejemplo =D de la simulación con la cópula t-Student:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiGgmCRSPZIa"
      },
      "source": [
        "x = rs.randn(n, m)\n",
        "x = np.matrix(x)\n",
        "\n",
        "v = (n - 1) * m\n",
        "V = rs.chisquare(v, size = (n, 1))\n",
        "\n",
        "s4 = np.sqrt(v/V) * np.array(x * L.T)\n",
        "U4 = st.t.cdf(s4, v)\n",
        "\n",
        "x4 = st.t.ppf(U4, v)\n",
        "#x4[:,0] = st.norm.ppf(U4[:,0])\n",
        "#x4[:,1] = st.t.ppf(U4[:,1], df = 2)\n",
        "#x4[:,2] = st.uniform.ppf(U4[:,2])\n",
        "\n",
        "correl_4 = np.corrcoef(x4.T)\n",
        "\n",
        "print(\"Matriz de Correlación Original:\")\n",
        "print(correl)\n",
        "print(\"\")\n",
        "print(\"Matriz de Correlación Simulada sin el ajuste:\")\n",
        "print(correl_4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0okRMWlfPog2"
      },
      "source": [
        "\n",
        "Se aprecia que al igual que para las copulas gaussianas, la aproximación no es muy buena. Si aplicamos el truco de anterior"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFDjGJo4PpJ2"
      },
      "source": [
        "x = rs.randn(n, m)\n",
        "x = np.matrix(np.sqrt(v/V) * np.array(x))\n",
        "\n",
        "for i in range(0,3):\n",
        "    c1 = np.cov(x.T)\n",
        "    L1 = np.linalg.cholesky(c1)\n",
        "    L1 = np.matrix(L1).I\n",
        "    x = x * L1.T\n",
        "\n",
        "s5 = x * L.T\n",
        "U5 = st.t.cdf(s5, v)\n",
        "\n",
        "x5 = st.t.ppf(U5, v)\n",
        "\n",
        "correl_5 = np.corrcoef(x5.T)\n",
        "\n",
        "print(\"Matriz de Correlación Original:\")\n",
        "print(correl)\n",
        "print(\"\")\n",
        "print(\"Matriz de Correlación Simulada con el ajuste:\")\n",
        "print(correl_5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3g-k4E7Pte_"
      },
      "source": [
        "Ahora pueden ver que la correlacion ha mejorado comparado a la simulación anterior.\n",
        "\n",
        "Usando la simulación anterior aplicaremos las inversas acumulativas de las distribuciones normal, t y uniforme para calcular las nuevas distribuciones correlacionadas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOSyVEW2PuWn"
      },
      "source": [
        "x6 = st.t.ppf(U5, v)\n",
        "x6[:,0] = st.norm.ppf(U5[:,0])\n",
        "x6[:,1] = st.t.ppf(U5[:,1], df = n - 1)\n",
        "x6[:,2] = st.uniform.ppf(U5[:,2])\n",
        "\n",
        "correl_6 = np.corrcoef(x6.T)\n",
        "\n",
        "print(\"Matriz de Correlación Original:\")\n",
        "print(correl)\n",
        "print(\"\")\n",
        "print(\"Matriz de Correlación Simulada con el ajuste:\")\n",
        "print(correl_6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKgtZF71P0I3"
      },
      "source": [
        "hist_scatter(x6[:,0], x6[:,2])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}