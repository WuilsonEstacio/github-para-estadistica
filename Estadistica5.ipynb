{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Estadistica5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNK50OPZpHF9zwVFvz5mwS6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WuilsonEstacio/github-para-estadistica/blob/main/Estadistica5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHwWSFuAQwsk"
      },
      "source": [
        "# Multiple linear regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXPIcAMVSGMq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "ca2c4bb6-4cdb-491a-ee03-26b92c84945d"
      },
      "source": [
        "pip install statsmodels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.6/dist-packages (0.10.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from statsmodels) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.18 in /usr/local/lib/python3.6/dist-packages (from statsmodels) (1.4.1)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from statsmodels) (0.5.1)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.6/dist-packages (from statsmodels) (1.0.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.4.0->statsmodels) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19->statsmodels) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19->statsmodels) (2018.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UHp7z15Qs-5"
      },
      "source": [
        "import pandas as pd\n",
        "import statsmodels.formula.api as smf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IULK-M-VQ3hQ"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrIYdOG6Q5q6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "0119d992-5232-466a-bad8-85bfce10f623"
      },
      "source": [
        "# import all stock market data into DataFrame\n",
        "aord = pd.DataFrame.from_csv('../data/indice/ALLOrdinary.csv')\n",
        "nikkei = pd.DataFrame.from_csv('../data/indice/Nikkei225.csv')\n",
        "hsi = pd.DataFrame.from_csv('../data/indice/HSI.csv')\n",
        "daxi = pd.DataFrame.from_csv('../data/indice/DAXI.csv')\n",
        "cac40 = pd.DataFrame.from_csv('../data/indice/CAC40.csv')\n",
        "sp500 = pd.DataFrame.from_csv('../data/indice/SP500.csv')\n",
        "dji = pd.DataFrame.from_csv('../data/indice/DJI.csv')\n",
        "nasdaq = pd.DataFrame.from_csv('../data/indice/nasdaq_composite.csv')\n",
        "spy = pd.DataFrame.from_csv('../data/indice/SPY.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-d12f2444fcf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# import all stock market data into DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/indice/ALLOrdinary.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnikkei\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/indice/Nikkei225.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mhsi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/indice/HSI.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdaxi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/indice/DAXI.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: type object 'DataFrame' has no attribute 'from_csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUAkdCkGQ9X7"
      },
      "source": [
        "nasdaq.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2wEnCwsRADj"
      },
      "source": [
        "# **Step 1: Data Munging**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBox1lkTRBUC"
      },
      "source": [
        "# Due to the timezone issues, we extract and calculate appropriate stock market data for analysis\n",
        "# Indicepanel is the DataFrame of our trading model\n",
        "indicepanel=pd.DataFrame(index=spy.index)\n",
        "\n",
        "indicepanel['spy']=spy['Open'].shift(-1)-spy['Open']\n",
        "indicepanel['spy_lag1']=indicepanel['spy'].shift(1)\n",
        "indicepanel['sp500']=sp500[\"Open\"]-sp500['Open'].shift(1)\n",
        "indicepanel['nasdaq']=nasdaq['Open']-nasdaq['Open'].shift(1)\n",
        "indicepanel['dji']=dji['Open']-dji['Open'].shift(1)\n",
        "\n",
        "indicepanel['cac40']=cac40['Open']-cac40['Open'].shift(1)\n",
        "indicepanel['daxi']=daxi['Open']-daxi['Open'].shift(1)\n",
        "\n",
        "indicepanel['aord']=aord['Close']-aord['Open']\n",
        "indicepanel['hsi']=hsi['Close']-hsi['Open']\n",
        "indicepanel['nikkei']=nikkei['Close']-nikkei['Open']\n",
        "indicepanel['Price']=spy['Open']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cb3Q5YXRRFvi"
      },
      "source": [
        "indicepanel.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VE5Q3x4RL_e"
      },
      "source": [
        "# Lets check whether do we have NaN values in indicepanel\n",
        "indicepanel.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5QtKupYRQXf"
      },
      "source": [
        "# We can use method 'fillna()' from dataframe to forward filling the Nan values\n",
        "# Then we can drop the reminding Nan values\n",
        "indicepanel = indicepanel.fillna(method='ffill')\n",
        "indicepanel = indicepanel.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoQFlmhNRSiO"
      },
      "source": [
        "# Lets check whether do we have Nan values in indicepanel now\n",
        "indicepanel.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWlqx77URTJM"
      },
      "source": [
        "# save this indicepanel for part 4.5\n",
        "path_save = '../data/indice/indicepanel.csv'\n",
        "indicepanel.to_csv(path_save)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wfjaWv-RdWs"
      },
      "source": [
        "print(indicepanel.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PutQBx1nRg0U"
      },
      "source": [
        "# **Step 2: Data Spliting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qd3L0zc4ReIs"
      },
      "source": [
        "#split the data into (1)train set and (2)test set\n",
        "\n",
        "Train = indicepanel.iloc[-2000:-1000, :]\n",
        "Test = indicepanel.iloc[-1000:, :]\n",
        "print(Train.shape, Test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iabwkfYtRj8z"
      },
      "source": [
        "# **Step 3: Explore the train data set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zu-tN-f1RmUG"
      },
      "source": [
        "# Generate scatter matrix among all stock markets (and the price of SPY) to observe the association\n",
        "\n",
        "from pandas.tools.plotting import scatter_matrix\n",
        "sm = scatter_matrix(Train, figsize=(10, 10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNxCo8otRqnD"
      },
      "source": [
        "# **Step 4: Check the correlation of each index between spy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATE6AoKCRrq0"
      },
      "source": [
        "# Find the indice with largest correlation\n",
        "corr_array = Train.iloc[:, :-1].corr()['spy']\n",
        "print(corr_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iarRMcKRtkM"
      },
      "source": [
        "formula = 'spy~spy_lag1+sp500+nasdaq+dji+cac40+aord+daxi+nikkei+hsi'\n",
        "lm = smf.ols(formula=formula, data=Train).fit()\n",
        "lm.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCuY3ErqRxMB"
      },
      "source": [
        "# **Step 5: Make prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TAR8Tw2RybU"
      },
      "source": [
        "Train['PredictedY'] = lm.predict(Train)\n",
        "Test['PredictedY'] = lm.predict(Test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAJmiu0kR0SU"
      },
      "source": [
        "plt.scatter(Train['spy'], Train['PredictedY'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-a_K5ZiFR4eU"
      },
      "source": [
        "# **Step 6: Model evaluation - Statistical standard**\n",
        "\n",
        "We can measure the performance of our model using some statistical metrics - RMSE, Adjusted  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KDw1DwMR9Bu"
      },
      "source": [
        "# RMSE - Root Mean Squared Error, Adjusted R^2\n",
        "def adjustedMetric(data, model, model_k, yname):\n",
        "    data['yhat'] = model.predict(data)\n",
        "    SST = ((data[yname] - data[yname].mean())**2).sum()\n",
        "    SSR = ((data['yhat'] - data[yname].mean())**2).sum()\n",
        "    SSE = ((data[yname] - data['yhat'])**2).sum()\n",
        "    r2 = SSR/SST\n",
        "    adjustR2 = 1 - (1-r2)*(data.shape[0] - 1)/(data.shape[0] -model_k -1)\n",
        "    RMSE = (SSE/(data.shape[0] -model_k -1))**0.5\n",
        "    return adjustR2, RMSE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bOM1h__R9wu"
      },
      "source": [
        "def assessTable(test, train, model, model_k, yname):\n",
        "    r2test, RMSEtest = adjustedMetric(test, model, model_k, yname)\n",
        "    r2train, RMSEtrain = adjustedMetric(train, model, model_k, yname)\n",
        "    assessment = pd.DataFrame(index=['R2', 'RMSE'], columns=['Train', 'Test'])\n",
        "    assessment['Train'] = [r2train, RMSEtrain]\n",
        "    assessment['Test'] = [r2test, RMSEtest]\n",
        "    return assessment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHLa8lcaR_jI"
      },
      "source": [
        "# Get the assement table fo our model\n",
        "assessTable(Test, Train, lm, 9, 'spy')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}